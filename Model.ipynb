{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This file do the following things.\n",
    "1. Define the model\n",
    "2. Read the training and testing dataset\n",
    "3. Train and test the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import all neccasary modules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 73
    },
    "id": "EcKHByXooe2I",
    "outputId": "407b580a-6200-402c-9aae-9fb9a3d43625"
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "from sklearn import preprocessing, model_selection\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "import argparse\n",
    "from argparse import RawTextHelpFormatter, RawDescriptionHelpFormatter\n",
    "import os\n",
    "from scipy import stats\n",
    "from tqdm import tqdm\n",
    "import csv\n",
    "from tensorflow.python.client import device_lib \n",
    "from numba import cuda\n",
    "import gc\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define loss function here.\n",
    "There are two loss functions: RMSE and PCC. I combined these two loss functions for training the model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "ggdhOwgEmV4J"
   },
   "outputs": [],
   "source": [
    "def rmse(y_true, y_pred):\n",
    "    dev = np.square(y_true.ravel() - y_pred.ravel())\n",
    "    return np.sqrt(np.sum(dev) / y_true.shape[0])\n",
    "\n",
    "\n",
    "def pcc(y_true, y_pred):\n",
    "    p = stats.pearsonr(y_true, y_pred)\n",
    "    if(math.isnan(p[0])): return 0.25\n",
    "    return p[0]\n",
    "\n",
    "\n",
    "def pcc_rmse(y_true, y_pred):\n",
    "\n",
    "    return (1-pcc(y_true, y_pred))*alpha + rmse(y_true, y_pred) * (1 - alpha)\n",
    "\n",
    "\n",
    "def PCC_RMSE(y_true, y_pred):\n",
    "    global alpha\n",
    "\n",
    "    fsp = y_pred - tf.keras.backend.mean(y_pred)\n",
    "    fst = y_true - tf.keras.backend.mean(y_true)\n",
    "\n",
    "    devP = tf.keras.backend.std(y_pred)\n",
    "    devT = tf.keras.backend.std(y_true)\n",
    "\n",
    "    r = tf.keras.backend.sqrt(tf.keras.backend.mean(tf.keras.backend.square(y_pred - y_true), axis=-1))\n",
    "    r = tf.where(tf.math.is_nan(r), 1.5, r)\n",
    "    \n",
    "    p = tf.keras.backend.mean(fsp * fst) / (devP * devT)\n",
    "    p = tf.where(tf.math.is_nan(p), 0.75, p)\n",
    "    p = 1 - p\n",
    "   \n",
    "\n",
    "    return alpha * p + (1 - alpha) * r\n",
    "\n",
    "\n",
    "def RMSE(y_true, y_pred):\n",
    "    return tf.keras.backend.sqrt(tf.keras.backend.mean(tf.keras.backend.square(y_pred - y_true), axis=-1))\n",
    "\n",
    "\n",
    "def PCC(y_true, y_pred):\n",
    "    fsp = y_pred - tf.keras.backend.mean(y_pred)\n",
    "    fst = y_true - tf.keras.backend.mean(y_true)\n",
    "\n",
    "    devP = tf.keras.backend.std(y_pred)\n",
    "    devT = tf.keras.backend.std(y_true)\n",
    "\n",
    "    p = tf.keras.backend.mean(fsp * fst) / (devP * devT)\n",
    "    \n",
    "    p = tf.where(tf.math.is_nan(p), 0.25, p)\n",
    "    \n",
    "    return p"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This function return a model to be trained. \n",
    "The model mostly consists of two dimentional convolution layers and dense layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "shMpkycnoIgr"
   },
   "outputs": [],
   "source": [
    "def create_model(input_size, lr=0.0001, maxpool=True, dropout=0.1):\n",
    "    model = tf.keras.Sequential()\n",
    "\n",
    "    model.add(tf.keras.layers.Conv2D(32, kernel_size=4, strides=1,\n",
    "                                     padding=\"valid\", input_shape=input_size))\n",
    "    model.add(tf.keras.layers.Activation(\"relu\"))\n",
    "    if maxpool:\n",
    "        model.add(tf.keras.layers.MaxPooling2D(\n",
    "            pool_size=2,\n",
    "            strides=2,\n",
    "            padding='same',  # Padding method\n",
    "        ))\n",
    "\n",
    "    model.add(tf.keras.layers.Conv2D(64, 4, 1, padding=\"valid\"))\n",
    "    model.add(tf.keras.layers.Activation(\"relu\"))\n",
    "    if maxpool:\n",
    "        model.add(tf.keras.layers.MaxPooling2D(\n",
    "            pool_size=2,\n",
    "            strides=2,\n",
    "            padding='same',  # Padding method\n",
    "        ))\n",
    "\n",
    "    model.add(tf.keras.layers.Conv2D(128, 4, 1, padding=\"valid\"))\n",
    "    model.add(tf.keras.layers.Activation(\"relu\"))\n",
    "    if maxpool:\n",
    "        model.add(tf.keras.layers.MaxPooling2D(\n",
    "            pool_size=2,\n",
    "            strides=2,\n",
    "            padding='same',  # Padding method\n",
    "        ))\n",
    "\n",
    "    model.add(tf.keras.layers.Flatten())\n",
    "\n",
    "    model.add(tf.keras.layers.Dense(400, kernel_regularizer=tf.keras.regularizers.l2(0.01), ))\n",
    "    model.add(tf.keras.layers.Activation(\"relu\"))\n",
    "    model.add(tf.keras.layers.BatchNormalization())\n",
    "    model.add(tf.keras.layers.Dropout(dropout))\n",
    "\n",
    "    model.add(tf.keras.layers.Dense(200,\n",
    "                                    kernel_regularizer=tf.keras.regularizers.l2(0.01), ))\n",
    "    model.add(tf.keras.layers.Activation(\"relu\"))\n",
    "    model.add(tf.keras.layers.BatchNormalization())\n",
    "    model.add(tf.keras.layers.Dropout(dropout))\n",
    "\n",
    "    model.add(tf.keras.layers.Dense(100, kernel_regularizer=tf.keras.regularizers.l2(0.01), ))\n",
    "    model.add(tf.keras.layers.Activation(\"relu\"))\n",
    "    model.add(tf.keras.layers.BatchNormalization())\n",
    "    model.add(tf.keras.layers.Dropout(dropout))\n",
    "\n",
    "    #model.add(tf.keras.layers.Dense(20, kernel_regularizer=tf.keras.regularizers.l2(0.01), ))\n",
    "    #model.add(tf.keras.layers.Activation(\"relu\"))\n",
    "    #model.add(tf.keras.layers.BatchNormalization())\n",
    "    #model.add(tf.keras.layers.Dropout(dropout))\n",
    "\n",
    "    model.add(tf.keras.layers.Dense(1, kernel_regularizer=tf.keras.regularizers.l2(0.01), ))\n",
    "    model.add(tf.keras.layers.Activation(\"relu\"))\n",
    "\n",
    "    sgd = tf.keras.optimizers.SGD(lr=lr, momentum=0.9, decay=1e-6, )\n",
    "    model.compile(optimizer=sgd, loss=PCC_RMSE, metrics=['mse'])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "uhBX_O00oL8S"
   },
   "outputs": [],
   "source": [
    "reshape = [81,80,1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define path files and read the input from the csv.\n",
    "Note that the inputs are already preprocessed in https://github.com/Sav-eng/protein-ligand-term-project/blob/main/Generate_features.ipynb."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "chYOmT0zoV04"
   },
   "outputs": [],
   "source": [
    "#change path\n",
    "train_file = \"train_test_validate_set/80_cutoffs_Ki_Kd/train.csv\"\n",
    "val_file = \"train_test_validate_set/80_cutoffs_Ki_Kd/validate.csv\"\n",
    "test_file = \"train_test_validate_set/80_cutoffs_Ki_Kd/test.csv\"\n",
    "path = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtrain = pd.read_csv(path + train_file,index_col=0,header = 0,names = None).dropna().values[:,1:-2]\n",
    "Xtest = pd.read_csv(path + test_file,index_col=0,header = 0,names = None).dropna().values[:,1:-2]\n",
    "Xval = pd.read_csv(path + val_file,index_col=0,header = 0,names = None).dropna().values[:,1:-2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "9656it [00:15, 607.44it/s]\n",
      "350it [00:01, 327.80it/s]\n",
      "1000it [00:01, 671.04it/s]\n"
     ]
    }
   ],
   "source": [
    "ytrain = []\n",
    "df = pd.read_csv(path + train_file,index_col=0,header = 0,names = None).dropna()\n",
    "for index,row in tqdm(df.iterrows()):\n",
    "  ytrain = ytrain + [row.values[-1]]\n",
    "\n",
    "ytest = []\n",
    "df = pd.read_csv(path + test_file,index_col=0,header = 0,names = None).dropna()\n",
    "for index,row in tqdm(df.iterrows()):\n",
    "  ytest = ytest + [row.values[-2]]\n",
    "\n",
    "yval = []\n",
    "df = pd.read_csv(path + val_file,index_col=0,header = 0,names = None).dropna()\n",
    "for index,row in tqdm(df.iterrows()):\n",
    "  yval = yval + [row.values[-2]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Xtrain.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "mGOdeRupJVWV",
    "outputId": "a2986f01-106f-402b-b1f0-a8d9916070e8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StandardScaler()"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler = preprocessing.StandardScaler()\n",
    "X_train_val = np.concatenate((Xtrain, Xval), axis=0)\n",
    "scaler.fit(X_train_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "wLRhC6lpJfLb"
   },
   "outputs": [],
   "source": [
    "Xtrain = scaler.transform(Xtrain).reshape(-1, reshape[0],reshape[1],reshape[2])\n",
    "Xval = scaler.transform(Xval).reshape(-1, reshape[0],reshape[1],reshape[2])\n",
    "Xtest = scaler.transform(Xtest).reshape(-1, reshape[0],reshape[1],reshape[2])\n",
    "ytrain = np.array(ytrain).reshape(-1, 1)\n",
    "yval = np.array(yval).reshape(-1, 1)\n",
    "ytest = np.array(ytest).reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 13807518564472134463\n",
      ", name: \"/device:XLA_CPU:0\"\n",
      "device_type: \"XLA_CPU\"\n",
      "memory_limit: 17179869184\n",
      "locality {\n",
      "}\n",
      "incarnation: 4060896302102920564\n",
      "physical_device_desc: \"device: XLA_CPU device\"\n",
      ", name: \"/device:GPU:0\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 9188828800\n",
      "locality {\n",
      "  bus_id: 2\n",
      "  numa_node: 1\n",
      "  links {\n",
      "  }\n",
      "}\n",
      "incarnation: 18200563814209533745\n",
      "physical_device_desc: \"device: 0, name: GeForce GTX 1080 Ti, pci bus id: 0000:86:00.0, compute capability: 6.1\"\n",
      ", name: \"/device:XLA_GPU:0\"\n",
      "device_type: \"XLA_GPU\"\n",
      "memory_limit: 17179869184\n",
      "locality {\n",
      "}\n",
      "incarnation: 3204343632277805997\n",
      "physical_device_desc: \"device: XLA_GPU device\"\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "print(device_lib.list_local_devices()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "53sE-rzoyXEZ"
   },
   "outputs": [],
   "source": [
    "log = []\n",
    "stop = [[0,999.9], ]\n",
    "batch_size = 128\n",
    "epochs = 500\n",
    "global alpha\n",
    "alpha = 0.8\n",
    "patience = 40\n",
    "path_model = \"models/final/\"\n",
    "path_log = \"logs/final/\"\n",
    "model_name = \"80_cutoffs_Ki_Kd.h5\"\n",
    "log_name = \"80_cutoffs_Ki_Kd.csv\"\n",
    "delta_loss = 0.01\n",
    "lr = 0.001\n",
    "dropout = 0\n",
    "maxpool = False\n",
    "model = create_model((reshape[0], reshape[1], reshape[2]),\n",
    "                                 lr=lr, dropout=dropout, maxpool=maxpool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cuda.select_device(0)\n",
    "# cuda.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train and test the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "eNvr1GdzyGwj",
    "outputId": "621fd983-310f-4051-fcd1-165a2fabba12"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "76/76 [==============================] - 13s 173ms/step - loss: 13.0304 - mse: 19.1461 - val_loss: 13.3051 - val_mse: 40.8990\n",
      "[0.        0.        0.        ... 0.9836105 0.2885653 0.6930298]\n",
      "EPOCH:1 Loss:1.676 RMSE:6.107 PCC:0.432 LOSS_VAL:1.642 RMSE_VAL:6.395 PCC_VAL:0.547 LOSS_TEST:1.695 RMSE_TEST:6.414 PCC_TEST:0.485\n",
      "76/76 [==============================] - 12s 164ms/step - loss: 12.4727 - mse: 13.7754 - val_loss: 12.7407 - val_mse: 30.9382\n",
      "[0.        0.        0.592468  ... 1.9131669 1.4319898 1.5125682]\n",
      "EPOCH:2 Loss:1.405 RMSE:5.314 PCC:0.572 LOSS_VAL:1.416 RMSE_VAL:5.562 PCC_VAL:0.620 LOSS_TEST:1.450 RMSE_TEST:5.623 PCC_TEST:0.594\n",
      "76/76 [==============================] - 13s 165ms/step - loss: 12.0503 - mse: 12.0078 - val_loss: 12.2565 - val_mse: 24.1158\n",
      "[0.        0.        1.1692796 ... 2.8493145 1.9758022 2.560081 ]\n",
      "EPOCH:3 Loss:1.252 RMSE:4.722 PCC:0.616 LOSS_VAL:1.273 RMSE_VAL:4.911 PCC_VAL:0.636 LOSS_TEST:1.300 RMSE_TEST:4.958 PCC_TEST:0.615\n",
      "76/76 [==============================] - 12s 164ms/step - loss: 11.6583 - mse: 10.8701 - val_loss: 11.7371 - val_mse: 15.9778\n",
      "[0.        0.        3.3648903 ... 4.2043858 3.1953192 3.9403956]\n",
      "EPOCH:4 Loss:1.073 RMSE:3.814 PCC:0.612 LOSS_VAL:1.119 RMSE_VAL:3.997 PCC_VAL:0.601 LOSS_TEST:1.082 RMSE_TEST:3.925 PCC_TEST:0.629\n",
      "76/76 [==============================] - 13s 165ms/step - loss: 11.2897 - mse: 10.0688 - val_loss: 11.2821 - val_mse: 11.7296\n",
      "[0.        0.        4.0548754 ... 5.1697025 3.3038766 4.86213  ]\n",
      "EPOCH:5 Loss:0.954 RMSE:3.317 PCC:0.637 LOSS_VAL:1.002 RMSE_VAL:3.425 PCC_VAL:0.604 LOSS_TEST:0.951 RMSE_TEST:3.312 PCC_TEST:0.639\n",
      "76/76 [==============================] - 13s 165ms/step - loss: 10.9201 - mse: 9.0945 - val_loss: 10.8848 - val_mse: 9.8868\n",
      "[0.        0.        3.8767412 ... 5.755801  4.201081  4.8725185]\n",
      "EPOCH:6 Loss:0.856 RMSE:2.962 PCC:0.670 LOSS_VAL:0.932 RMSE_VAL:3.144 PCC_VAL:0.621 LOSS_TEST:0.856 RMSE_TEST:2.958 PCC_TEST:0.670\n",
      "76/76 [==============================] - 13s 165ms/step - loss: 10.5917 - mse: 8.6525 - val_loss: 10.5164 - val_mse: 8.2169\n",
      "[0.        0.        4.91423   ... 6.7320027 4.7266045 6.064879 ]\n",
      "EPOCH:7 Loss:0.798 RMSE:2.673 PCC:0.671 LOSS_VAL:0.883 RMSE_VAL:2.867 PCC_VAL:0.613 LOSS_TEST:0.826 RMSE_TEST:2.714 PCC_TEST:0.646\n",
      "76/76 [==============================] - 13s 165ms/step - loss: 10.2651 - mse: 8.1707 - val_loss: 10.2338 - val_mse: 9.1255\n",
      "[0.        0.        3.876721  ... 7.9662027 4.058068  5.984849 ]\n",
      "EPOCH:8 Loss:0.779 RMSE:2.771 PCC:0.719 LOSS_VAL:0.894 RMSE_VAL:3.021 PCC_VAL:0.638 LOSS_TEST:0.829 RMSE_TEST:2.857 PCC_TEST:0.678\n",
      "76/76 [==============================] - 13s 166ms/step - loss: 9.9493 - mse: 7.7257 - val_loss: 9.9807 - val_mse: 9.3538\n",
      "[0.        0.        3.2227361 ... 9.605687  4.507093  5.9382343]\n",
      "EPOCH:9 Loss:0.761 RMSE:2.771 PCC:0.742 LOSS_VAL:0.902 RMSE_VAL:3.058 PCC_VAL:0.638 LOSS_TEST:0.845 RMSE_TEST:2.914 PCC_TEST:0.672\n",
      "76/76 [==============================] - 13s 166ms/step - loss: 9.6541 - mse: 7.4319 - val_loss: 9.6060 - val_mse: 6.9384\n",
      "[0.       0.       4.165941 ... 9.108107 4.398487 7.709782]\n",
      "EPOCH:10 Loss:0.681 RMSE:2.376 PCC:0.742 LOSS_VAL:0.810 RMSE_VAL:2.634 PCC_VAL:0.646 LOSS_TEST:0.769 RMSE_TEST:2.450 PCC_TEST:0.651\n",
      "76/76 [==============================] - 13s 165ms/step - loss: 9.3658 - mse: 7.0108 - val_loss: 9.3574 - val_mse: 7.9002\n",
      "[0.        0.        2.9489746 ... 9.00351   3.783877  7.5349736]\n",
      "EPOCH:11 Loss:0.686 RMSE:2.525 PCC:0.774 LOSS_VAL:0.833 RMSE_VAL:2.811 PCC_VAL:0.662 LOSS_TEST:0.773 RMSE_TEST:2.620 PCC_TEST:0.689\n",
      "76/76 [==============================] - 13s 165ms/step - loss: 9.0697 - mse: 6.4582 - val_loss: 9.0862 - val_mse: 7.2778\n",
      "[0.        0.        4.3125687 ... 6.476476  4.496472  7.222729 ]\n",
      "EPOCH:12 Loss:0.661 RMSE:2.409 PCC:0.777 LOSS_VAL:0.811 RMSE_VAL:2.698 PCC_VAL:0.660 LOSS_TEST:0.745 RMSE_TEST:2.456 PCC_TEST:0.683\n",
      "76/76 [==============================] - 13s 165ms/step - loss: 8.8015 - mse: 6.1340 - val_loss: 8.7956 - val_mse: 6.3008\n",
      "[0.        0.        4.14028   ... 9.801459  4.7765584 7.569461 ]\n",
      "EPOCH:13 Loss:0.620 RMSE:2.252 PCC:0.789 LOSS_VAL:0.763 RMSE_VAL:2.510 PCC_VAL:0.674 LOSS_TEST:0.700 RMSE_TEST:2.256 PCC_TEST:0.690\n",
      "76/76 [==============================] - 13s 166ms/step - loss: 8.5508 - mse: 5.9536 - val_loss: 8.5722 - val_mse: 6.3254\n",
      "[ 0.         0.         4.123755  ... 10.001788   4.3680887  7.369666 ]\n",
      "EPOCH:14 Loss:0.620 RMSE:2.221 PCC:0.780 LOSS_VAL:0.780 RMSE_VAL:2.515 PCC_VAL:0.654 LOSS_TEST:0.712 RMSE_TEST:2.251 PCC_TEST:0.673\n",
      "76/76 [==============================] - 13s 166ms/step - loss: 8.2786 - mse: 5.4464 - val_loss: 8.3194 - val_mse: 5.5716\n",
      "[0.        2.545614  3.4423752 ... 9.8827715 4.1902323 6.67986  ]\n",
      "EPOCH:15 Loss:0.579 RMSE:2.053 PCC:0.789 LOSS_VAL:0.756 RMSE_VAL:2.360 PCC_VAL:0.645 LOSS_TEST:0.720 RMSE_TEST:2.143 PCC_TEST:0.635\n",
      "76/76 [==============================] - 13s 165ms/step - loss: 8.0455 - mse: 5.3664 - val_loss: 8.1134 - val_mse: 7.0175\n",
      "[0.        0.        2.867199  ... 9.939967  3.5557985 7.407485 ]\n",
      "EPOCH:16 Loss:0.606 RMSE:2.298 PCC:0.817 LOSS_VAL:0.788 RMSE_VAL:2.649 PCC_VAL:0.677 LOSS_TEST:0.746 RMSE_TEST:2.526 PCC_TEST:0.699\n",
      "76/76 [==============================] - 13s 165ms/step - loss: 7.7892 - mse: 4.8742 - val_loss: 7.8273 - val_mse: 5.0820\n",
      "[0.        4.8875093 6.000825  ... 7.8210306 4.3890305 5.5291367]\n",
      "EPOCH:17 Loss:0.523 RMSE:1.924 PCC:0.827 LOSS_VAL:0.704 RMSE_VAL:2.254 PCC_VAL:0.684 LOSS_TEST:0.687 RMSE_TEST:2.118 PCC_TEST:0.670\n",
      "76/76 [==============================] - 13s 165ms/step - loss: 7.5461 - mse: 4.2399 - val_loss: 7.6366 - val_mse: 5.4051\n",
      "[0.        6.7241626 2.6265666 ... 8.6367655 4.2915225 6.7483463]\n",
      "EPOCH:18 Loss:0.506 RMSE:1.910 PCC:0.844 LOSS_VAL:0.727 RMSE_VAL:2.325 PCC_VAL:0.673 LOSS_TEST:0.713 RMSE_TEST:2.261 PCC_TEST:0.674\n",
      "76/76 [==============================] - 13s 165ms/step - loss: 7.3150 - mse: 3.8291 - val_loss: 7.4011 - val_mse: 4.5163\n",
      "[0.        5.1530557 5.7758913 ... 9.129665  3.5434313 7.552191 ]\n",
      "EPOCH:19 Loss:0.479 RMSE:1.760 PCC:0.842 LOSS_VAL:0.687 RMSE_VAL:2.125 PCC_VAL:0.673 LOSS_TEST:0.659 RMSE_TEST:1.940 PCC_TEST:0.661\n",
      "76/76 [==============================] - 13s 165ms/step - loss: 7.0917 - mse: 3.6030 - val_loss: 7.2785 - val_mse: 6.9906\n",
      "[0.        4.877417  0.        ... 8.268137  2.6823716 7.675603 ]\n",
      "EPOCH:20 Loss:0.572 RMSE:2.228 PCC:0.842 LOSS_VAL:0.789 RMSE_VAL:2.644 PCC_VAL:0.675 LOSS_TEST:0.759 RMSE_TEST:2.547 PCC_TEST:0.688\n",
      "76/76 [==============================] - 13s 165ms/step - loss: 6.8786 - mse: 3.3295 - val_loss: 6.9804 - val_mse: 4.1655\n",
      "[0.        5.7102785 5.0510883 ... 8.958936  3.9562714 7.088151 ]\n",
      "EPOCH:21 Loss:0.440 RMSE:1.661 PCC:0.865 LOSS_VAL:0.659 RMSE_VAL:2.041 PCC_VAL:0.687 LOSS_TEST:0.645 RMSE_TEST:1.931 PCC_TEST:0.676\n",
      "76/76 [==============================] - 13s 165ms/step - loss: 6.6719 - mse: 3.1094 - val_loss: 6.7758 - val_mse: 3.7635\n",
      "[ 0.         5.0893154  4.753476  ... 10.930245   4.5779366  7.703653 ]\n",
      "EPOCH:22 Loss:0.423 RMSE:1.550 PCC:0.859 LOSS_VAL:0.639 RMSE_VAL:1.940 PCC_VAL:0.686 LOSS_TEST:0.653 RMSE_TEST:1.928 PCC_TEST:0.666\n",
      "76/76 [==============================] - 13s 165ms/step - loss: 6.4743 - mse: 2.9073 - val_loss: 6.6028 - val_mse: 4.1215\n",
      "[0.        3.9624429 2.7128892 ... 9.179933  4.2134333 6.672444 ]\n",
      "EPOCH:23 Loss:0.408 RMSE:1.601 PCC:0.890 LOSS_VAL:0.646 RMSE_VAL:2.030 PCC_VAL:0.700 LOSS_TEST:0.613 RMSE_TEST:1.888 PCC_TEST:0.706\n",
      "76/76 [==============================] - 13s 165ms/step - loss: 6.2713 - mse: 2.6541 - val_loss: 6.4044 - val_mse: 3.2387\n",
      "[0.        4.70611   4.223564  ... 8.674129  4.7705736 6.820776 ]\n",
      "EPOCH:24 Loss:0.379 RMSE:1.388 PCC:0.874 LOSS_VAL:0.617 RMSE_VAL:1.800 PCC_VAL:0.679 LOSS_TEST:0.605 RMSE_TEST:1.732 PCC_TEST:0.676\n",
      "76/76 [==============================] - 13s 165ms/step - loss: 6.0919 - mse: 2.5787 - val_loss: 6.2649 - val_mse: 4.6729\n",
      "[0.        4.7611713 3.4725432 ... 9.489428  4.188142  7.3812943]\n",
      "EPOCH:25 Loss:0.426 RMSE:1.703 PCC:0.894 LOSS_VAL:0.671 RMSE_VAL:2.162 PCC_VAL:0.702 LOSS_TEST:0.670 RMSE_TEST:2.111 PCC_TEST:0.690\n",
      "76/76 [==============================] - 13s 166ms/step - loss: 5.9027 - mse: 2.4125 - val_loss: 6.0504 - val_mse: 3.7063\n",
      "[ 0.         5.4859133  3.6224198 ... 10.166811   4.1911945  6.8632975]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH:26 Loss:0.379 RMSE:1.490 PCC:0.899 LOSS_VAL:0.617 RMSE_VAL:1.925 PCC_VAL:0.711 LOSS_TEST:0.644 RMSE_TEST:1.935 PCC_TEST:0.679\n",
      "76/76 [==============================] - 13s 165ms/step - loss: 5.7406 - mse: 2.4038 - val_loss: 5.8887 - val_mse: 3.0596\n",
      "[0.        4.370194  4.8596225 ... 9.980976  4.621877  7.367809 ]\n",
      "EPOCH:27 Loss:0.365 RMSE:1.344 PCC:0.880 LOSS_VAL:0.599 RMSE_VAL:1.749 PCC_VAL:0.689 LOSS_TEST:0.603 RMSE_TEST:1.721 PCC_TEST:0.677\n",
      "76/76 [==============================] - 13s 166ms/step - loss: 5.5703 - mse: 2.2403 - val_loss: 5.7293 - val_mse: 3.6006\n",
      "[ 0.        4.685373  4.084828 ... 10.606867  3.654325  7.967782]\n",
      "EPOCH:28 Loss:0.365 RMSE:1.452 PCC:0.906 LOSS_VAL:0.607 RMSE_VAL:1.898 PCC_VAL:0.716 LOSS_TEST:0.597 RMSE_TEST:1.791 PCC_TEST:0.702\n",
      "76/76 [==============================] - 13s 165ms/step - loss: 5.4039 - mse: 2.1335 - val_loss: 5.5829 - val_mse: 3.8865\n",
      "[0.        4.389107  3.5128424 ... 9.194675  4.349574  6.5814624]\n",
      "EPOCH:29 Loss:0.370 RMSE:1.492 PCC:0.911 LOSS_VAL:0.620 RMSE_VAL:1.971 PCC_VAL:0.718 LOSS_TEST:0.594 RMSE_TEST:1.837 PCC_TEST:0.717\n",
      "76/76 [==============================] - 13s 166ms/step - loss: 5.2429 - mse: 2.0585 - val_loss: 5.4276 - val_mse: 3.3936\n",
      "[0.        4.50056   4.1065516 ... 8.323071  4.4315457 7.0025992]\n",
      "EPOCH:30 Loss:0.359 RMSE:1.388 PCC:0.898 LOSS_VAL:0.611 RMSE_VAL:1.842 PCC_VAL:0.696 LOSS_TEST:0.585 RMSE_TEST:1.728 PCC_TEST:0.701\n",
      "76/76 [==============================] - 13s 165ms/step - loss: 5.0982 - mse: 2.0363 - val_loss: 5.2723 - val_mse: 3.0069\n",
      "[0.        4.340653  4.175142  ... 8.752743  4.5752535 7.212325 ]\n",
      "EPOCH:31 Loss:0.354 RMSE:1.321 PCC:0.888 LOSS_VAL:0.593 RMSE_VAL:1.734 PCC_VAL:0.692 LOSS_TEST:0.621 RMSE_TEST:1.740 PCC_TEST:0.659\n",
      "76/76 [==============================] - 12s 164ms/step - loss: 4.9640 - mse: 2.1150 - val_loss: 5.1164 - val_mse: 3.1329\n",
      "[0.        3.8977654 4.1561794 ... 9.816168  4.0370626 7.304547 ]\n",
      "EPOCH:32 Loss:0.341 RMSE:1.354 PCC:0.912 LOSS_VAL:0.577 RMSE_VAL:1.770 PCC_VAL:0.722 LOSS_TEST:0.593 RMSE_TEST:1.750 PCC_TEST:0.697\n",
      "76/76 [==============================] - 13s 165ms/step - loss: 4.8014 - mse: 1.9082 - val_loss: 4.9819 - val_mse: 3.0877\n",
      "[0.        4.739438  3.6385057 ... 9.498396  4.1525383 7.6434364]\n",
      "EPOCH:33 Loss:0.337 RMSE:1.320 PCC:0.908 LOSS_VAL:0.579 RMSE_VAL:1.757 PCC_VAL:0.716 LOSS_TEST:0.589 RMSE_TEST:1.710 PCC_TEST:0.692\n",
      "76/76 [==============================] - 13s 165ms/step - loss: 4.6709 - mse: 1.8655 - val_loss: 4.8403 - val_mse: 2.8352\n",
      "[0.        5.0573945 4.3334455 ... 9.37754   4.65891   7.4459386]\n",
      "EPOCH:34 Loss:0.328 RMSE:1.264 PCC:0.905 LOSS_VAL:0.562 RMSE_VAL:1.684 PCC_VAL:0.718 LOSS_TEST:0.580 RMSE_TEST:1.670 PCC_TEST:0.693\n",
      "76/76 [==============================] - 13s 165ms/step - loss: 4.5349 - mse: 1.8279 - val_loss: 4.7253 - val_mse: 3.2373\n",
      "[0.        5.7037373 3.4519036 ... 8.757435  4.4157534 6.874362 ]\n",
      "EPOCH:35 Loss:0.340 RMSE:1.338 PCC:0.910 LOSS_VAL:0.588 RMSE_VAL:1.799 PCC_VAL:0.715 LOSS_TEST:0.616 RMSE_TEST:1.816 PCC_TEST:0.684\n",
      "76/76 [==============================] - 13s 165ms/step - loss: 4.4016 - mse: 1.7295 - val_loss: 4.5734 - val_mse: 2.4249\n",
      "[0.       5.781737 4.312563 ... 8.955047 4.827664 7.207431]\n",
      "EPOCH:36 Loss:0.301 RMSE:1.115 PCC:0.903 LOSS_VAL:0.544 RMSE_VAL:1.557 PCC_VAL:0.709 LOSS_TEST:0.543 RMSE_TEST:1.524 PCC_TEST:0.702\n",
      "76/76 [==============================] - 13s 165ms/step - loss: 4.2809 - mse: 1.7439 - val_loss: 4.4729 - val_mse: 2.8413\n",
      "[0.        5.2352257 4.1913853 ... 8.930126  4.4278197 7.4929748]\n",
      "EPOCH:37 Loss:0.317 RMSE:1.199 PCC:0.903 LOSS_VAL:0.576 RMSE_VAL:1.686 PCC_VAL:0.702 LOSS_TEST:0.581 RMSE_TEST:1.636 PCC_TEST:0.683\n",
      "76/76 [==============================] - 13s 165ms/step - loss: 4.1680 - mse: 1.7990 - val_loss: 4.3846 - val_mse: 3.3453\n",
      "[0.        4.3883457 3.7270498 ... 9.042714  4.6044974 7.5571246]\n",
      "EPOCH:38 Loss:0.334 RMSE:1.313 PCC:0.911 LOSS_VAL:0.598 RMSE_VAL:1.829 PCC_VAL:0.709 LOSS_TEST:0.599 RMSE_TEST:1.774 PCC_TEST:0.695\n",
      "76/76 [==============================] - 13s 165ms/step - loss: 4.0325 - mse: 1.5338 - val_loss: 4.2220 - val_mse: 2.4653\n",
      "[ 0.         4.4665937  4.282486  ... 10.218945   4.9341416  7.1355295]\n",
      "EPOCH:39 Loss:0.299 RMSE:1.117 PCC:0.906 LOSS_VAL:0.543 RMSE_VAL:1.570 PCC_VAL:0.713 LOSS_TEST:0.567 RMSE_TEST:1.574 PCC_TEST:0.684\n",
      "76/76 [==============================] - 13s 165ms/step - loss: 3.9233 - mse: 1.5507 - val_loss: 4.1144 - val_mse: 2.6080\n",
      "[0.        4.917148  4.2050295 ... 9.4246645 4.4223    7.875816 ]\n",
      "EPOCH:40 Loss:0.290 RMSE:1.117 PCC:0.916 LOSS_VAL:0.549 RMSE_VAL:1.615 PCC_VAL:0.717 LOSS_TEST:0.556 RMSE_TEST:1.585 PCC_TEST:0.701\n",
      "76/76 [==============================] - 13s 164ms/step - loss: 3.8080 - mse: 1.4843 - val_loss: 4.0182 - val_mse: 2.7145\n",
      "[0.        5.044959  3.8897922 ... 8.237004  4.188307  7.4231005]\n",
      "EPOCH:41 Loss:0.300 RMSE:1.158 PCC:0.915 LOSS_VAL:0.562 RMSE_VAL:1.648 PCC_VAL:0.709 LOSS_TEST:0.572 RMSE_TEST:1.639 PCC_TEST:0.695\n",
      "76/76 [==============================] - 13s 165ms/step - loss: 3.6900 - mse: 1.3460 - val_loss: 3.9029 - val_mse: 2.5693\n",
      "[0.        5.284402  4.335624  ... 8.970003  4.7464085 7.1782107]\n",
      "EPOCH:42 Loss:0.279 RMSE:1.073 PCC:0.920 LOSS_VAL:0.549 RMSE_VAL:1.603 PCC_VAL:0.714 LOSS_TEST:0.523 RMSE_TEST:1.504 PCC_TEST:0.723\n",
      "76/76 [==============================] - 13s 165ms/step - loss: 3.5858 - mse: 1.3096 - val_loss: 3.7975 - val_mse: 2.5321\n",
      "[0.        4.962021  4.5840755 ... 9.218579  4.0003963 7.2032194]\n",
      "EPOCH:43 Loss:0.274 RMSE:1.052 PCC:0.921 LOSS_VAL:0.544 RMSE_VAL:1.591 PCC_VAL:0.718 LOSS_TEST:0.545 RMSE_TEST:1.541 PCC_TEST:0.704\n",
      "76/76 [==============================] - 13s 165ms/step - loss: 3.4846 - mse: 1.2686 - val_loss: 3.7066 - val_mse: 2.4479\n",
      "[0.        4.811658  3.9676423 ... 9.405911  3.9044883 7.238695 ]\n",
      "EPOCH:44 Loss:0.270 RMSE:1.040 PCC:0.922 LOSS_VAL:0.548 RMSE_VAL:1.565 PCC_VAL:0.707 LOSS_TEST:0.553 RMSE_TEST:1.544 PCC_TEST:0.695\n",
      "76/76 [==============================] - 13s 166ms/step - loss: 3.3879 - mse: 1.2377 - val_loss: 3.6286 - val_mse: 2.8690\n",
      "[0.        4.359663  4.1321225 ... 8.422168  4.548187  7.122851 ]\n",
      "EPOCH:45 Loss:0.291 RMSE:1.144 PCC:0.923 LOSS_VAL:0.565 RMSE_VAL:1.694 PCC_VAL:0.717 LOSS_TEST:0.558 RMSE_TEST:1.651 PCC_TEST:0.715\n",
      "76/76 [==============================] - 12s 164ms/step - loss: 3.2908 - mse: 1.1805 - val_loss: 3.5209 - val_mse: 2.4108\n",
      "[0.        5.517682  4.4590874 ... 9.125622  3.7706056 6.8797092]\n",
      "EPOCH:46 Loss:0.257 RMSE:0.991 PCC:0.926 LOSS_VAL:0.543 RMSE_VAL:1.553 PCC_VAL:0.709 LOSS_TEST:0.556 RMSE_TEST:1.564 PCC_TEST:0.696\n",
      "76/76 [==============================] - 13s 172ms/step - loss: 3.2096 - mse: 1.2595 - val_loss: 3.4389 - val_mse: 2.7910\n",
      "[0.        4.785123  3.8507266 ... 8.127413  3.9528017 7.0262976]\n",
      "EPOCH:47 Loss:0.278 RMSE:1.120 PCC:0.932 LOSS_VAL:0.551 RMSE_VAL:1.671 PCC_VAL:0.729 LOSS_TEST:0.566 RMSE_TEST:1.661 PCC_TEST:0.708\n",
      "76/76 [==============================] - 13s 165ms/step - loss: 3.1033 - mse: 1.0598 - val_loss: 3.3285 - val_mse: 2.0914\n",
      "[0.        5.646371  4.8197713 ... 9.24782   4.53623   7.1663046]\n",
      "EPOCH:48 Loss:0.234 RMSE:0.872 PCC:0.926 LOSS_VAL:0.521 RMSE_VAL:1.446 PCC_VAL:0.711 LOSS_TEST:0.520 RMSE_TEST:1.429 PCC_TEST:0.707\n",
      "76/76 [==============================] - 13s 165ms/step - loss: 3.0226 - mse: 1.0893 - val_loss: 3.2425 - val_mse: 2.1832\n",
      "[0.        4.5588675 4.2382402 ... 8.832113  4.6755595 7.483743 ]\n",
      "EPOCH:49 Loss:0.237 RMSE:0.893 PCC:0.927 LOSS_VAL:0.525 RMSE_VAL:1.478 PCC_VAL:0.713 LOSS_TEST:0.513 RMSE_TEST:1.434 PCC_TEST:0.718\n",
      "76/76 [==============================] - 13s 165ms/step - loss: 2.9345 - mse: 1.0449 - val_loss: 3.1952 - val_mse: 2.8302\n",
      "[0.        5.309989  4.0585513 ... 7.820282  4.5666656 6.9914017]\n",
      "EPOCH:50 Loss:0.286 RMSE:1.122 PCC:0.923 LOSS_VAL:0.563 RMSE_VAL:1.682 PCC_VAL:0.717 LOSS_TEST:0.589 RMSE_TEST:1.696 PCC_TEST:0.687\n",
      "76/76 [==============================] - 13s 165ms/step - loss: 2.8532 - mse: 1.0488 - val_loss: 3.0771 - val_mse: 2.0687\n",
      "[0.        5.201419  4.214068  ... 9.1729    4.3803678 7.361907 ]\n",
      "EPOCH:51 Loss:0.224 RMSE:0.841 PCC:0.931 LOSS_VAL:0.515 RMSE_VAL:1.438 PCC_VAL:0.716 LOSS_TEST:0.514 RMSE_TEST:1.429 PCC_TEST:0.715\n",
      "76/76 [==============================] - 13s 165ms/step - loss: 2.7723 - mse: 0.9778 - val_loss: 3.0085 - val_mse: 2.1075\n",
      "[0.        5.2505856 4.642566  ... 9.340062  4.4889483 7.142939 ]\n",
      "EPOCH:52 Loss:0.224 RMSE:0.854 PCC:0.933 LOSS_VAL:0.519 RMSE_VAL:1.452 PCC_VAL:0.714 LOSS_TEST:0.527 RMSE_TEST:1.463 PCC_TEST:0.707\n",
      "76/76 [==============================] - 13s 165ms/step - loss: 2.6809 - mse: 0.8556 - val_loss: 2.9323 - val_mse: 2.2907\n",
      "[0.        5.1284447 3.783797  ... 9.09871   4.6244307 8.1593275]\n",
      "EPOCH:53 Loss:0.230 RMSE:0.918 PCC:0.942 LOSS_VAL:0.519 RMSE_VAL:1.513 PCC_VAL:0.729 LOSS_TEST:0.522 RMSE_TEST:1.502 PCC_TEST:0.724\n",
      "76/76 [==============================] - 13s 165ms/step - loss: 2.6179 - mse: 0.9484 - val_loss: 2.8367 - val_mse: 1.9791\n",
      "[0.        4.6600604 4.359432  ... 8.402387  4.2132845 7.783286 ]\n",
      "EPOCH:54 Loss:0.222 RMSE:0.866 PCC:0.939 LOSS_VAL:0.484 RMSE_VAL:1.407 PCC_VAL:0.747 LOSS_TEST:0.496 RMSE_TEST:1.424 PCC_TEST:0.736\n",
      "76/76 [==============================] - 13s 165ms/step - loss: 2.5418 - mse: 0.8957 - val_loss: 2.7908 - val_mse: 2.2281\n",
      "[0.        4.455209  4.016773  ... 9.020938  4.0531454 6.9620614]\n",
      "EPOCH:55 Loss:0.230 RMSE:0.911 PCC:0.940 LOSS_VAL:0.517 RMSE_VAL:1.493 PCC_VAL:0.727 LOSS_TEST:0.540 RMSE_TEST:1.523 PCC_TEST:0.706\n",
      "76/76 [==============================] - 13s 165ms/step - loss: 2.4704 - mse: 0.8619 - val_loss: 2.6961 - val_mse: 1.8888\n",
      "[0.        5.5154757 4.039959  ... 9.335753  4.5546923 7.017322 ]\n",
      "EPOCH:56 Loss:0.207 RMSE:0.802 PCC:0.942 LOSS_VAL:0.482 RMSE_VAL:1.374 PCC_VAL:0.741 LOSS_TEST:0.485 RMSE_TEST:1.381 PCC_TEST:0.740\n",
      "76/76 [==============================] - 13s 165ms/step - loss: 2.3949 - mse: 0.7798 - val_loss: 2.6363 - val_mse: 1.9460\n",
      "[0.        4.7317557 4.289067  ... 8.616838  4.401125  7.344654 ]\n",
      "EPOCH:57 Loss:0.206 RMSE:0.795 PCC:0.941 LOSS_VAL:0.489 RMSE_VAL:1.395 PCC_VAL:0.737 LOSS_TEST:0.512 RMSE_TEST:1.435 PCC_TEST:0.719\n",
      "76/76 [==============================] - 12s 164ms/step - loss: 2.3264 - mse: 0.7514 - val_loss: 2.5775 - val_mse: 2.0390\n",
      "[0.        4.574579  4.248503  ... 8.994618  4.630993  7.8049564]\n",
      "EPOCH:58 Loss:0.213 RMSE:0.836 PCC:0.943 LOSS_VAL:0.493 RMSE_VAL:1.428 PCC_VAL:0.741 LOSS_TEST:0.512 RMSE_TEST:1.452 PCC_TEST:0.723\n",
      "76/76 [==============================] - 13s 165ms/step - loss: 2.2669 - mse: 0.7441 - val_loss: 2.5318 - val_mse: 1.9948\n",
      "[5.956224  5.4262395 4.4331813 ... 9.260157  4.491855  7.193289 ]\n",
      "EPOCH:59 Loss:0.224 RMSE:0.821 PCC:0.925 LOSS_VAL:0.511 RMSE_VAL:1.412 PCC_VAL:0.714 LOSS_TEST:0.561 RMSE_TEST:1.504 PCC_TEST:0.675\n",
      "76/76 [==============================] - 13s 165ms/step - loss: 2.1971 - mse: 0.6701 - val_loss: 2.4268 - val_mse: 1.7367\n",
      "[3.0337238 5.3993874 4.365322  ... 8.638416  4.9346514 7.8614054]\n",
      "EPOCH:60 Loss:0.183 RMSE:0.711 PCC:0.950 LOSS_VAL:0.460 RMSE_VAL:1.318 PCC_VAL:0.754 LOSS_TEST:0.480 RMSE_TEST:1.353 PCC_TEST:0.739\n",
      "76/76 [==============================] - 13s 165ms/step - loss: 2.1392 - mse: 0.6818 - val_loss: 2.3775 - val_mse: 1.7896\n",
      "[3.669115  4.937452  4.6535115 ... 8.823762  5.2082696 7.2599406]\n",
      "EPOCH:61 Loss:0.173 RMSE:0.674 PCC:0.952 LOSS_VAL:0.470 RMSE_VAL:1.338 PCC_VAL:0.747 LOSS_TEST:0.485 RMSE_TEST:1.363 PCC_TEST:0.735\n",
      "76/76 [==============================] - 13s 165ms/step - loss: 2.0815 - mse: 0.6825 - val_loss: 2.3357 - val_mse: 2.0375\n",
      "[3.3885188 5.573789  4.2812757 ... 7.8251686 4.7082796 7.1033726]\n",
      "EPOCH:62 Loss:0.212 RMSE:0.853 PCC:0.948 LOSS_VAL:0.485 RMSE_VAL:1.427 PCC_VAL:0.751 LOSS_TEST:0.499 RMSE_TEST:1.445 PCC_TEST:0.737\n",
      "76/76 [==============================] - 13s 165ms/step - loss: 2.0206 - mse: 0.6471 - val_loss: 2.2800 - val_mse: 2.0777\n",
      "[2.8310816 5.965363  4.089032  ... 8.505264  4.131252  6.9938583]\n",
      "EPOCH:63 Loss:0.205 RMSE:0.845 PCC:0.955 LOSS_VAL:0.485 RMSE_VAL:1.441 PCC_VAL:0.754 LOSS_TEST:0.495 RMSE_TEST:1.452 PCC_TEST:0.744\n",
      "76/76 [==============================] - 13s 165ms/step - loss: 1.9717 - mse: 0.6785 - val_loss: 2.2167 - val_mse: 1.8399\n",
      "[3.2530184 5.555094  4.3277125 ... 8.582504  4.4664636 7.1475344]\n",
      "EPOCH:64 Loss:0.170 RMSE:0.672 PCC:0.955 LOSS_VAL:0.473 RMSE_VAL:1.356 PCC_VAL:0.747 LOSS_TEST:0.488 RMSE_TEST:1.382 PCC_TEST:0.735\n",
      "76/76 [==============================] - 12s 164ms/step - loss: 1.9137 - mse: 0.6294 - val_loss: 2.1630 - val_mse: 1.8039\n",
      "[3.8506577 5.9356384 4.3032827 ... 8.233349  4.314184  7.2776003]\n",
      "EPOCH:65 Loss:0.168 RMSE:0.655 PCC:0.953 LOSS_VAL:0.471 RMSE_VAL:1.343 PCC_VAL:0.747 LOSS_TEST:0.506 RMSE_TEST:1.413 PCC_TEST:0.721\n",
      "76/76 [==============================] - 13s 165ms/step - loss: 1.8548 - mse: 0.5930 - val_loss: 2.0942 - val_mse: 1.6874\n",
      "[4.264592  5.174427  4.3685255 ... 8.67073   4.558479  7.653822 ]\n",
      "EPOCH:66 Loss:0.149 RMSE:0.587 PCC:0.961 LOSS_VAL:0.452 RMSE_VAL:1.299 PCC_VAL:0.759 LOSS_TEST:0.483 RMSE_TEST:1.362 PCC_TEST:0.737\n",
      "76/76 [==============================] - 12s 164ms/step - loss: 1.7937 - mse: 0.4800 - val_loss: 2.0748 - val_mse: 1.9713\n",
      "[2.0829487 4.8844275 4.172606  ... 9.230551  4.4561863 7.3367443]\n",
      "EPOCH:67 Loss:0.199 RMSE:0.785 PCC:0.947 LOSS_VAL:0.481 RMSE_VAL:1.404 PCC_VAL:0.749 LOSS_TEST:0.530 RMSE_TEST:1.503 PCC_TEST:0.713\n",
      "76/76 [==============================] - 13s 165ms/step - loss: 1.7506 - mse: 0.5379 - val_loss: 2.0070 - val_mse: 1.7548\n",
      "[2.9199789 5.253236  4.277743  ... 8.370214  4.6354656 7.546075 ]\n",
      "EPOCH:68 Loss:0.159 RMSE:0.631 PCC:0.959 LOSS_VAL:0.459 RMSE_VAL:1.325 PCC_VAL:0.757 LOSS_TEST:0.474 RMSE_TEST:1.361 PCC_TEST:0.747\n",
      "76/76 [==============================] - 13s 165ms/step - loss: 1.7035 - mse: 0.5288 - val_loss: 1.9637 - val_mse: 1.8153\n",
      "[3.658712  5.0512905 4.42094   ... 8.968353  4.5269427 6.82445  ]\n",
      "EPOCH:69 Loss:0.152 RMSE:0.629 PCC:0.967 LOSS_VAL:0.464 RMSE_VAL:1.347 PCC_VAL:0.757 LOSS_TEST:0.484 RMSE_TEST:1.383 PCC_TEST:0.740\n",
      "76/76 [==============================] - 13s 165ms/step - loss: 1.6558 - mse: 0.5317 - val_loss: 1.9156 - val_mse: 1.7194\n",
      "[4.43419   5.0192122 4.332101  ... 8.524316  4.51646   7.119841 ]\n",
      "EPOCH:70 Loss:0.144 RMSE:0.576 PCC:0.965 LOSS_VAL:0.459 RMSE_VAL:1.311 PCC_VAL:0.754 LOSS_TEST:0.496 RMSE_TEST:1.388 PCC_TEST:0.727\n",
      "76/76 [==============================] - 13s 165ms/step - loss: 1.6130 - mse: 0.5152 - val_loss: 1.8858 - val_mse: 1.8946\n",
      "[3.42192   5.275575  4.4877295 ... 9.143878  4.271852  7.1387167]\n",
      "EPOCH:71 Loss:0.159 RMSE:0.661 PCC:0.967 LOSS_VAL:0.472 RMSE_VAL:1.376 PCC_VAL:0.754 LOSS_TEST:0.495 RMSE_TEST:1.422 PCC_TEST:0.737\n",
      "76/76 [==============================] - 12s 164ms/step - loss: 1.5695 - mse: 0.5156 - val_loss: 1.8340 - val_mse: 1.8481\n",
      "[3.522717  5.306004  4.1520376 ... 8.775233  4.2726526 7.0259247]\n",
      "EPOCH:72 Loss:0.163 RMSE:0.674 PCC:0.964 LOSS_VAL:0.462 RMSE_VAL:1.359 PCC_VAL:0.762 LOSS_TEST:0.513 RMSE_TEST:1.456 PCC_TEST:0.723\n",
      "76/76 [==============================] - 12s 164ms/step - loss: 1.5233 - mse: 0.4727 - val_loss: 1.7954 - val_mse: 1.7967\n",
      "[5.319965  5.1921887 4.314897  ... 8.824481  4.3826084 7.4319754]\n",
      "EPOCH:73 Loss:0.151 RMSE:0.615 PCC:0.965 LOSS_VAL:0.463 RMSE_VAL:1.340 PCC_VAL:0.756 LOSS_TEST:0.492 RMSE_TEST:1.402 PCC_TEST:0.736\n",
      "76/76 [==============================] - 13s 165ms/step - loss: 1.4853 - mse: 0.4902 - val_loss: 1.7642 - val_mse: 1.8622\n",
      "[2.986371  5.6206203 4.180826  ... 9.217518  4.6849327 7.2341976]\n",
      "EPOCH:74 Loss:0.167 RMSE:0.668 PCC:0.958 LOSS_VAL:0.474 RMSE_VAL:1.365 PCC_VAL:0.749 LOSS_TEST:0.498 RMSE_TEST:1.406 PCC_TEST:0.729\n",
      "76/76 [==============================] - 13s 165ms/step - loss: 1.4406 - mse: 0.4529 - val_loss: 1.7044 - val_mse: 1.7010\n",
      "[3.355547  5.181335  4.297761  ... 8.721614  4.8995314 7.256399 ]\n",
      "EPOCH:75 Loss:0.139 RMSE:0.564 PCC:0.968 LOSS_VAL:0.451 RMSE_VAL:1.304 PCC_VAL:0.763 LOSS_TEST:0.483 RMSE_TEST:1.366 PCC_TEST:0.738\n",
      "76/76 [==============================] - 13s 165ms/step - loss: 1.3992 - mse: 0.4345 - val_loss: 1.6659 - val_mse: 1.7002\n",
      "[4.0061574 5.130725  4.4496903 ... 8.720495  4.713842  7.3961363]\n",
      "EPOCH:76 Loss:0.139 RMSE:0.570 PCC:0.968 LOSS_VAL:0.449 RMSE_VAL:1.304 PCC_VAL:0.764 LOSS_TEST:0.481 RMSE_TEST:1.371 PCC_TEST:0.741\n",
      "76/76 [==============================] - 12s 164ms/step - loss: 1.3610 - mse: 0.4310 - val_loss: 1.6291 - val_mse: 1.6695\n",
      "[3.8465362 5.285119  4.3503847 ... 8.921387  4.521817  7.4084682]\n",
      "EPOCH:77 Loss:0.137 RMSE:0.555 PCC:0.968 LOSS_VAL:0.448 RMSE_VAL:1.292 PCC_VAL:0.763 LOSS_TEST:0.477 RMSE_TEST:1.355 PCC_TEST:0.743\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "76/76 [==============================] - 13s 166ms/step - loss: 1.3251 - mse: 0.4322 - val_loss: 1.5966 - val_mse: 1.6838\n",
      "[3.7072506 5.103301  4.283154  ... 8.549236  4.830148  7.0009294]\n",
      "EPOCH:78 Loss:0.136 RMSE:0.544 PCC:0.966 LOSS_VAL:0.453 RMSE_VAL:1.298 PCC_VAL:0.759 LOSS_TEST:0.474 RMSE_TEST:1.348 PCC_TEST:0.744\n",
      "76/76 [==============================] - 13s 165ms/step - loss: 1.2879 - mse: 0.4275 - val_loss: 1.5666 - val_mse: 1.7268\n",
      "[4.0621862 5.3131227 4.227267  ... 8.828173  4.642809  7.0330143]\n",
      "EPOCH:79 Loss:0.131 RMSE:0.539 PCC:0.970 LOSS_VAL:0.458 RMSE_VAL:1.314 PCC_VAL:0.757 LOSS_TEST:0.491 RMSE_TEST:1.390 PCC_TEST:0.734\n",
      "76/76 [==============================] - 13s 166ms/step - loss: 1.2567 - mse: 0.4289 - val_loss: 1.5310 - val_mse: 1.6719\n",
      "[3.9301195 5.387334  4.6396804 ... 8.524789  4.366781  7.5520134]\n",
      "EPOCH:80 Loss:0.135 RMSE:0.539 PCC:0.966 LOSS_VAL:0.452 RMSE_VAL:1.293 PCC_VAL:0.758 LOSS_TEST:0.484 RMSE_TEST:1.366 PCC_TEST:0.736\n",
      "76/76 [==============================] - 13s 165ms/step - loss: 1.2295 - mse: 0.4515 - val_loss: 1.5062 - val_mse: 1.7964\n",
      "[3.2963812 5.3613515 4.1506968 ... 8.474783  4.6249356 7.2424307]\n",
      "EPOCH:81 Loss:0.144 RMSE:0.594 PCC:0.968 LOSS_VAL:0.462 RMSE_VAL:1.340 PCC_VAL:0.758 LOSS_TEST:0.494 RMSE_TEST:1.408 PCC_TEST:0.735\n",
      "76/76 [==============================] - 13s 165ms/step - loss: 1.1907 - mse: 0.4102 - val_loss: 1.4647 - val_mse: 1.6493\n",
      "[4.0538564 5.8142853 4.2306542 ... 9.054437  4.4633083 7.4118648]\n",
      "EPOCH:82 Loss:0.125 RMSE:0.505 PCC:0.970 LOSS_VAL:0.449 RMSE_VAL:1.284 PCC_VAL:0.760 LOSS_TEST:0.490 RMSE_TEST:1.370 PCC_TEST:0.730\n",
      "76/76 [==============================] - 13s 165ms/step - loss: 1.1586 - mse: 0.4053 - val_loss: 1.4354 - val_mse: 1.7035\n",
      "[4.2543964 5.4643874 3.942377  ... 8.677913  4.335648  7.3354177]\n",
      "EPOCH:83 Loss:0.133 RMSE:0.544 PCC:0.970 LOSS_VAL:0.453 RMSE_VAL:1.305 PCC_VAL:0.761 LOSS_TEST:0.486 RMSE_TEST:1.377 PCC_TEST:0.737\n",
      "76/76 [==============================] - 13s 165ms/step - loss: 1.1299 - mse: 0.4133 - val_loss: 1.4202 - val_mse: 1.8277\n",
      "[4.1895676 5.363172  3.9079509 ... 8.990987  4.5157485 7.404276 ]\n",
      "EPOCH:84 Loss:0.145 RMSE:0.601 PCC:0.969 LOSS_VAL:0.466 RMSE_VAL:1.352 PCC_VAL:0.756 LOSS_TEST:0.503 RMSE_TEST:1.428 PCC_TEST:0.728\n",
      "76/76 [==============================] - 13s 165ms/step - loss: 1.1002 - mse: 0.4150 - val_loss: 1.4013 - val_mse: 1.9521\n",
      "[3.5362885 5.96746   4.127303  ... 8.756466  4.9012733 7.603184 ]\n",
      "EPOCH:85 Loss:0.160 RMSE:0.661 PCC:0.965 LOSS_VAL:0.476 RMSE_VAL:1.397 PCC_VAL:0.754 LOSS_TEST:0.499 RMSE_TEST:1.448 PCC_TEST:0.738\n",
      "76/76 [==============================] - 12s 164ms/step - loss: 1.0682 - mse: 0.3690 - val_loss: 1.3604 - val_mse: 1.7816\n",
      "[3.7972264 5.537285  3.9949903 ... 8.694759  4.559205  7.0527225]\n",
      "EPOCH:86 Loss:0.136 RMSE:0.556 PCC:0.969 LOSS_VAL:0.463 RMSE_VAL:1.335 PCC_VAL:0.756 LOSS_TEST:0.488 RMSE_TEST:1.391 PCC_TEST:0.738\n",
      "76/76 [==============================] - 13s 165ms/step - loss: 1.0426 - mse: 0.3697 - val_loss: 1.3225 - val_mse: 1.6847\n",
      "[3.9756885 5.1396184 4.1424775 ... 9.448336  4.561124  7.362976 ]\n",
      "EPOCH:87 Loss:0.128 RMSE:0.525 PCC:0.971 LOSS_VAL:0.450 RMSE_VAL:1.298 PCC_VAL:0.763 LOSS_TEST:0.481 RMSE_TEST:1.360 PCC_TEST:0.739\n",
      "76/76 [==============================] - 13s 165ms/step - loss: 1.0119 - mse: 0.3443 - val_loss: 1.2981 - val_mse: 1.6921\n",
      "[3.9142451 5.5154753 4.330578  ... 9.161081  4.860093  7.4986806]\n",
      "EPOCH:88 Loss:0.123 RMSE:0.511 PCC:0.974 LOSS_VAL:0.451 RMSE_VAL:1.301 PCC_VAL:0.761 LOSS_TEST:0.478 RMSE_TEST:1.360 PCC_TEST:0.743\n",
      "76/76 [==============================] - 13s 166ms/step - loss: 0.9863 - mse: 0.3521 - val_loss: 1.2627 - val_mse: 1.6234\n",
      "[4.091557  5.5726943 4.302409  ... 8.415933  4.6021028 7.527007 ]\n",
      "EPOCH:89 Loss:0.122 RMSE:0.502 PCC:0.973 LOSS_VAL:0.441 RMSE_VAL:1.274 PCC_VAL:0.767 LOSS_TEST:0.482 RMSE_TEST:1.362 PCC_TEST:0.738\n",
      "76/76 [==============================] - 13s 165ms/step - loss: 0.9555 - mse: 0.3270 - val_loss: 1.2453 - val_mse: 1.6582\n",
      "[3.7068143 4.8796086 4.501532  ... 9.206673  4.7477536 7.624381 ]\n",
      "EPOCH:90 Loss:0.122 RMSE:0.503 PCC:0.973 LOSS_VAL:0.448 RMSE_VAL:1.288 PCC_VAL:0.762 LOSS_TEST:0.472 RMSE_TEST:1.336 PCC_TEST:0.744\n",
      "76/76 [==============================] - 13s 165ms/step - loss: 0.9301 - mse: 0.3193 - val_loss: 1.2189 - val_mse: 1.6293\n",
      "[4.276056  5.101428  4.6504416 ... 9.269023  4.7458544 7.421408 ]\n",
      "EPOCH:91 Loss:0.114 RMSE:0.467 PCC:0.975 LOSS_VAL:0.445 RMSE_VAL:1.276 PCC_VAL:0.763 LOSS_TEST:0.480 RMSE_TEST:1.350 PCC_TEST:0.738\n",
      "76/76 [==============================] - 12s 164ms/step - loss: 0.9030 - mse: 0.2923 - val_loss: 1.2029 - val_mse: 1.7104\n",
      "[3.8071265 5.284477  4.543941  ... 9.350824  4.6126213 7.2658343]\n",
      "EPOCH:92 Loss:0.127 RMSE:0.521 PCC:0.971 LOSS_VAL:0.453 RMSE_VAL:1.308 PCC_VAL:0.761 LOSS_TEST:0.479 RMSE_TEST:1.365 PCC_TEST:0.742\n",
      "76/76 [==============================] - 13s 165ms/step - loss: 0.8777 - mse: 0.2347 - val_loss: 1.1749 - val_mse: 1.6308\n",
      "[4.1835403 5.592747  4.505973  ... 9.304338  4.630026  7.4501076]\n",
      "EPOCH:93 Loss:0.116 RMSE:0.472 PCC:0.972 LOSS_VAL:0.446 RMSE_VAL:1.277 PCC_VAL:0.761 LOSS_TEST:0.482 RMSE_TEST:1.353 PCC_TEST:0.736\n",
      "76/76 [==============================] - 13s 165ms/step - loss: 0.8550 - mse: 0.2343 - val_loss: 1.1698 - val_mse: 1.7071\n",
      "[4.7317038 5.1743064 4.3761177 ... 8.781718  4.572565  7.280033 ]\n",
      "EPOCH:94 Loss:0.096 RMSE:0.400 PCC:0.980 LOSS_VAL:0.463 RMSE_VAL:1.307 PCC_VAL:0.748 LOSS_TEST:0.485 RMSE_TEST:1.361 PCC_TEST:0.734\n",
      "76/76 [==============================] - 13s 165ms/step - loss: 0.8233 - mse: 0.1641 - val_loss: 1.1355 - val_mse: 1.6336\n",
      "[4.4964094 5.0070014 4.4085174 ... 8.599271  4.6268396 7.6337667]\n",
      "EPOCH:95 Loss:0.105 RMSE:0.428 PCC:0.976 LOSS_VAL:0.449 RMSE_VAL:1.278 PCC_VAL:0.758 LOSS_TEST:0.476 RMSE_TEST:1.339 PCC_TEST:0.740\n",
      "76/76 [==============================] - 13s 165ms/step - loss: 0.8000 - mse: 0.1509 - val_loss: 1.1149 - val_mse: 1.6362\n",
      "[4.6191196 5.5566263 4.4987164 ... 8.835392  4.7224245 7.0901823]\n",
      "EPOCH:96 Loss:0.091 RMSE:0.382 PCC:0.981 LOSS_VAL:0.449 RMSE_VAL:1.279 PCC_VAL:0.759 LOSS_TEST:0.479 RMSE_TEST:1.345 PCC_TEST:0.738\n",
      "76/76 [==============================] - 13s 165ms/step - loss: 0.7743 - mse: 0.1306 - val_loss: 1.0916 - val_mse: 1.6264\n",
      "[4.040777  5.4948206 4.5151777 ... 9.481005  4.6679096 7.5492473]\n",
      "EPOCH:97 Loss:0.068 RMSE:0.295 PCC:0.989 LOSS_VAL:0.447 RMSE_VAL:1.275 PCC_VAL:0.761 LOSS_TEST:0.471 RMSE_TEST:1.331 PCC_TEST:0.744\n",
      "76/76 [==============================] - 13s 165ms/step - loss: 0.7550 - mse: 0.1334 - val_loss: 1.0744 - val_mse: 1.6534\n",
      "[3.852655  5.8327227 4.302704  ... 8.778549  4.7575197 7.58041  ]\n",
      "EPOCH:98 Loss:0.069 RMSE:0.307 PCC:0.990 LOSS_VAL:0.448 RMSE_VAL:1.286 PCC_VAL:0.761 LOSS_TEST:0.473 RMSE_TEST:1.343 PCC_TEST:0.745\n",
      "76/76 [==============================] - 13s 165ms/step - loss: 0.7333 - mse: 0.1226 - val_loss: 1.0508 - val_mse: 1.6233\n",
      "[4.577771  5.2861423 4.8782    ... 9.095186  4.6089973 7.735844 ]\n",
      "EPOCH:99 Loss:0.083 RMSE:0.356 PCC:0.985 LOSS_VAL:0.443 RMSE_VAL:1.274 PCC_VAL:0.765 LOSS_TEST:0.480 RMSE_TEST:1.355 PCC_TEST:0.738\n",
      "76/76 [==============================] - 13s 165ms/step - loss: 0.7159 - mse: 0.1265 - val_loss: 1.0359 - val_mse: 1.6494\n",
      "[3.9287543 5.1882358 4.2817736 ... 8.81818   4.7002897 7.1000447]\n",
      "EPOCH:100 Loss:0.065 RMSE:0.292 PCC:0.991 LOSS_VAL:0.447 RMSE_VAL:1.284 PCC_VAL:0.762 LOSS_TEST:0.470 RMSE_TEST:1.336 PCC_TEST:0.746\n",
      "76/76 [==============================] - 13s 165ms/step - loss: 0.6944 - mse: 0.1167 - val_loss: 1.0146 - val_mse: 1.6234\n",
      "[4.1699758 5.6306877 4.593602  ... 8.991713  4.7406726 7.553112 ]\n",
      "EPOCH:101 Loss:0.055 RMSE:0.247 PCC:0.992 LOSS_VAL:0.444 RMSE_VAL:1.274 PCC_VAL:0.764 LOSS_TEST:0.479 RMSE_TEST:1.347 PCC_TEST:0.738\n",
      "76/76 [==============================] - 13s 165ms/step - loss: 0.6778 - mse: 0.1180 - val_loss: 0.9993 - val_mse: 1.6268\n",
      "[4.2598376 5.606495  4.5702386 ... 9.155743  4.794983  7.0265107]\n",
      "EPOCH:102 Loss:0.061 RMSE:0.268 PCC:0.991 LOSS_VAL:0.445 RMSE_VAL:1.275 PCC_VAL:0.762 LOSS_TEST:0.478 RMSE_TEST:1.349 PCC_TEST:0.739\n",
      "76/76 [==============================] - 12s 164ms/step - loss: 0.6612 - mse: 0.1211 - val_loss: 0.9879 - val_mse: 1.6837\n",
      "[4.095457  5.2214074 4.208561  ... 8.607216  4.4657097 7.306479 ]\n",
      "EPOCH:103 Loss:0.070 RMSE:0.314 PCC:0.991 LOSS_VAL:0.453 RMSE_VAL:1.298 PCC_VAL:0.759 LOSS_TEST:0.481 RMSE_TEST:1.359 PCC_TEST:0.739\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "76/76 [==============================] - 13s 165ms/step - loss: 0.6406 - mse: 0.1062 - val_loss: 0.9700 - val_mse: 1.6427\n",
      "[4.211195  4.7870336 4.3933773 ... 8.542194  4.6198626 7.362976 ]\n",
      "EPOCH:104 Loss:0.069 RMSE:0.303 PCC:0.989 LOSS_VAL:0.450 RMSE_VAL:1.282 PCC_VAL:0.758 LOSS_TEST:0.475 RMSE_TEST:1.340 PCC_TEST:0.741\n",
      "76/76 [==============================] - 13s 165ms/step - loss: 0.6257 - mse: 0.1112 - val_loss: 0.9547 - val_mse: 1.6584\n",
      "[4.326152  5.416295  4.8122654 ... 8.953906  4.841205  7.344272 ]\n",
      "EPOCH:105 Loss:0.075 RMSE:0.325 PCC:0.987 LOSS_VAL:0.451 RMSE_VAL:1.288 PCC_VAL:0.758 LOSS_TEST:0.476 RMSE_TEST:1.343 PCC_TEST:0.740\n",
      "76/76 [==============================] - 13s 165ms/step - loss: 0.6096 - mse: 0.1105 - val_loss: 0.9288 - val_mse: 1.6070\n",
      "[4.2218065 5.2464457 4.4934106 ... 8.806882  4.787158  7.2593346]\n",
      "EPOCH:106 Loss:0.061 RMSE:0.275 PCC:0.992 LOSS_VAL:0.440 RMSE_VAL:1.268 PCC_VAL:0.767 LOSS_TEST:0.473 RMSE_TEST:1.341 PCC_TEST:0.744\n",
      "76/76 [==============================] - 13s 165ms/step - loss: 0.5904 - mse: 0.0963 - val_loss: 0.9207 - val_mse: 1.6390\n",
      "[4.4668245 5.4385643 4.5689087 ... 8.770718  4.5507555 7.511446 ]\n",
      "EPOCH:107 Loss:0.057 RMSE:0.259 PCC:0.994 LOSS_VAL:0.446 RMSE_VAL:1.280 PCC_VAL:0.762 LOSS_TEST:0.476 RMSE_TEST:1.347 PCC_TEST:0.741\n",
      "76/76 [==============================] - 13s 165ms/step - loss: 0.5782 - mse: 0.1060 - val_loss: 0.9079 - val_mse: 1.6649\n",
      "[4.026619  5.7259974 4.467794  ... 9.254896  4.5996127 7.5785375]\n",
      "EPOCH:108 Loss:0.074 RMSE:0.322 PCC:0.988 LOSS_VAL:0.449 RMSE_VAL:1.290 PCC_VAL:0.762 LOSS_TEST:0.472 RMSE_TEST:1.340 PCC_TEST:0.745\n",
      "76/76 [==============================] - 13s 165ms/step - loss: 0.5638 - mse: 0.1073 - val_loss: 0.8914 - val_mse: 1.6364\n",
      "[3.5426147 5.552841  4.5854244 ... 8.730841  4.597861  7.521001 ]\n",
      "EPOCH:109 Loss:0.068 RMSE:0.297 PCC:0.989 LOSS_VAL:0.447 RMSE_VAL:1.279 PCC_VAL:0.761 LOSS_TEST:0.475 RMSE_TEST:1.341 PCC_TEST:0.741\n",
      "76/76 [==============================] - 13s 165ms/step - loss: 0.5508 - mse: 0.1088 - val_loss: 0.8746 - val_mse: 1.6214\n",
      "[4.089829  5.0705776 4.3880367 ... 8.855527  4.543761  7.5815663]\n",
      "EPOCH:110 Loss:0.055 RMSE:0.245 PCC:0.993 LOSS_VAL:0.443 RMSE_VAL:1.273 PCC_VAL:0.764 LOSS_TEST:0.468 RMSE_TEST:1.328 PCC_TEST:0.747\n",
      "76/76 [==============================] - 13s 165ms/step - loss: 0.5370 - mse: 0.1051 - val_loss: 0.8629 - val_mse: 1.6197\n",
      "[4.1560388 5.559833  4.4858394 ... 8.986324  4.5166707 7.5359693]\n",
      "EPOCH:111 Loss:0.060 RMSE:0.268 PCC:0.992 LOSS_VAL:0.445 RMSE_VAL:1.273 PCC_VAL:0.762 LOSS_TEST:0.476 RMSE_TEST:1.342 PCC_TEST:0.741\n",
      "76/76 [==============================] - 13s 165ms/step - loss: 0.5257 - mse: 0.1123 - val_loss: 0.8538 - val_mse: 1.6579\n",
      "[4.364453  5.415789  4.6080656 ... 8.909628  4.654087  7.4098496]\n",
      "EPOCH:112 Loss:0.057 RMSE:0.257 PCC:0.993 LOSS_VAL:0.450 RMSE_VAL:1.288 PCC_VAL:0.759 LOSS_TEST:0.471 RMSE_TEST:1.337 PCC_TEST:0.746\n",
      "76/76 [==============================] - 13s 165ms/step - loss: 0.5096 - mse: 0.1032 - val_loss: 0.8402 - val_mse: 1.6212\n",
      "[4.180928  5.4183965 4.6980467 ... 8.775636  4.8462644 7.6101384]\n",
      "EPOCH:113 Loss:0.066 RMSE:0.287 PCC:0.990 LOSS_VAL:0.447 RMSE_VAL:1.273 PCC_VAL:0.759 LOSS_TEST:0.474 RMSE_TEST:1.336 PCC_TEST:0.741\n",
      "76/76 [==============================] - 13s 165ms/step - loss: 0.4951 - mse: 0.0957 - val_loss: 0.8275 - val_mse: 1.6766\n",
      "[3.4915433 4.888545  4.344616  ... 9.039065  4.4328136 7.481517 ]\n",
      "EPOCH:114 Loss:0.065 RMSE:0.298 PCC:0.993 LOSS_VAL:0.448 RMSE_VAL:1.295 PCC_VAL:0.763 LOSS_TEST:0.476 RMSE_TEST:1.352 PCC_TEST:0.743\n",
      "76/76 [==============================] - 13s 165ms/step - loss: 0.4839 - mse: 0.0960 - val_loss: 0.8160 - val_mse: 1.6305\n",
      "[4.060227  5.1168084 4.576133  ... 8.710491  4.6976266 7.1877146]\n",
      "EPOCH:115 Loss:0.061 RMSE:0.267 PCC:0.991 LOSS_VAL:0.447 RMSE_VAL:1.277 PCC_VAL:0.760 LOSS_TEST:0.470 RMSE_TEST:1.329 PCC_TEST:0.745\n",
      "76/76 [==============================] - 13s 165ms/step - loss: 0.4700 - mse: 0.0903 - val_loss: 0.7989 - val_mse: 1.6012\n",
      "[4.1164155 5.482053  4.608946  ... 8.497976  4.6843157 7.2100034]\n",
      "EPOCH:116 Loss:0.053 RMSE:0.237 PCC:0.993 LOSS_VAL:0.442 RMSE_VAL:1.265 PCC_VAL:0.764 LOSS_TEST:0.472 RMSE_TEST:1.332 PCC_TEST:0.742\n",
      "Get best model at epoch = 76.\n"
     ]
    }
   ],
   "source": [
    "with open('generation.csv', mode='a') as generation_file:\n",
    "    generation_writer = csv.writer(generation_file, delimiter=',', quotechar='\"', quoting=csv.QUOTE_MINIMAL)\n",
    "    generation_writer.writerow([model_name, log_name, lr, dropout, maxpool, alpha, batch_size])\n",
    "\n",
    "for e in range(1, epochs+1):\n",
    "    model.fit(Xtrain, ytrain, validation_data=(Xval, yval),batch_size=batch_size, epochs=1, verbose=1)\n",
    "\n",
    "    ytrain_pred = model.predict(Xtrain).ravel()\n",
    "    print(ytrain_pred)\n",
    "    loss = pcc_rmse(ytrain.ravel(), ytrain_pred)\n",
    "    pcc_train = pcc(ytrain.ravel(), ytrain_pred)\n",
    "    rmse_train = rmse(ytrain.ravel(), ytrain_pred)\n",
    "\n",
    "    yval_pred = model.predict(Xval).ravel()\n",
    "    loss_val = pcc_rmse(yval.ravel(), yval_pred)\n",
    "    pcc_val = pcc(yval.ravel(), yval_pred)\n",
    "    rmse_val = rmse(yval.ravel(), yval_pred)\n",
    "\n",
    "    ytest_pred = model.predict(Xtest).ravel()\n",
    "    loss_test = pcc_rmse(ytest.ravel(), ytest_pred)\n",
    "    pcc_test = pcc(ytest.ravel(), ytest_pred)\n",
    "    rmse_test = rmse(ytest.ravel(), ytest_pred)\n",
    "\n",
    "    log.append([e, loss, pcc_train, rmse_train,\n",
    "                    loss_val, pcc_val, rmse_val,\n",
    "                    loss_test, pcc_test, rmse_test])\n",
    "    logs    = pd.DataFrame(log, columns=['epoch', 'loss', 'pcc_train', 'rmse_train',\n",
    "                                             'loss_val', 'pcc_val', 'rmse_val',\n",
    "                                             'loss_test', 'pcc_test', 'rmse_test'])\n",
    "\n",
    "    print(\"EPOCH:%d Loss:%.3f RMSE:%.3f PCC:%.3f LOSS_VAL:%.3f RMSE_VAL:%.3f PCC_VAL:%.3f LOSS_TEST:%.3f RMSE_TEST:%.3f PCC_TEST:%.3f\"%\n",
    "          (e, loss, rmse_train, pcc_train, loss_val, rmse_val, pcc_val, loss_test, rmse_test, pcc_test ))            \n",
    "\n",
    "    if(stop[-1][1] - loss_val >= delta_loss):\n",
    "#         print(\"Model improve from %.3f to %.3f. Save model to %s.\"% (stop[-1][1], loss_val, path_model + model_name))\n",
    "#         model.save(path_model + model_name)\n",
    "        stop.append([e, loss_val])\n",
    "    else:\n",
    "        if(e - stop[-1][0] >= patience):\n",
    "            print(\"Get best model at epoch = %d.\" % stop[-1][0])\n",
    "            break\n",
    "            \n",
    "logs.to_csv(path_log + log_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Model.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
